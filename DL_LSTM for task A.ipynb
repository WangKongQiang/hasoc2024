{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blond-share",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "democratic-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-reynolds",
   "metadata": {},
   "source": [
    "### Handling Pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statutory-athens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>task_1</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60c5d6bf5659ea5e55defa2c</td>\n",
       "      <td>HOF</td>\n",
       "      <td>made amp amp onli abl start make money sustain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60c5d6bf5659ea5e55def461</td>\n",
       "      <td>HOF</td>\n",
       "      <td>technic still turn back clock dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60c5d6bf5659ea5e55defaad</td>\n",
       "      <td>NOT</td>\n",
       "      <td>govt stop think world media liber gang ani opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60c5d6bf5659ea5e55def419</td>\n",
       "      <td>HOF</td>\n",
       "      <td>soldier japan dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60c5d6bf5659ea5e55def7fa</td>\n",
       "      <td>HOF</td>\n",
       "      <td>would better ask think sleazi shitbag lmao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                       _id task_1  \\\n",
       "0             0  60c5d6bf5659ea5e55defa2c    HOF   \n",
       "1             1  60c5d6bf5659ea5e55def461    HOF   \n",
       "2             2  60c5d6bf5659ea5e55defaad    NOT   \n",
       "3             3  60c5d6bf5659ea5e55def419    HOF   \n",
       "4             4  60c5d6bf5659ea5e55def7fa    HOF   \n",
       "\n",
       "                                          text_clean  \n",
       "0  made amp amp onli abl start make money sustain...  \n",
       "1            technic still turn back clock dick head  \n",
       "2  govt stop think world media liber gang ani opt...  \n",
       "3                            soldier japan dick head  \n",
       "4         would better ask think sleazi shitbag lmao  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../preprocess_data.csv')\n",
    "data.drop(['task_2','Unnamed: 0','text'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "double-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text_clean'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = 1500,split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neither-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words :  8255\n",
      "[[   0    0    0 ...  170    3  210]\n",
      " [   0    0    0 ...   72   54   73]\n",
      " [   0    0    0 ...    3   52   13]\n",
      " ...\n",
      " [   0    0    0 ...  817   45  156]\n",
      " [   0    0    0 ...  213   99   38]\n",
      " [   0    0    0 ... 1166  236   57]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_seq_len = 2500\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "print(\"No of unique words : \",len(index_of_words))\n",
    "\n",
    "X = pad_sequences(sequence , maxlen = max_seq_len )\n",
    "Y = data['task_1']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proved-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocabSize = len(index_of_words)\n",
    "lstm_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 0)\n",
    "Y_true = Y_test\n",
    "Y_train = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compact-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         2113280   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,195,586\n",
      "Trainable params: 2,195,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim,input_length = 2500))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "universal-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_a_2.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifteen-christianity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5873 - accuracy: 0.6935\n",
      "Epoch 1: val_loss improved from inf to 0.49795, saving model to hasoc_a_2.h5\n",
      "103/103 [==============================] - 425s 4s/step - loss: 0.5873 - accuracy: 0.6935 - val_loss: 0.4979 - val_accuracy: 0.7764\n",
      "Epoch 2/5\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8120\n",
      "Epoch 2: val_loss improved from 0.49795 to 0.49533, saving model to hasoc_a_2.h5\n",
      "103/103 [==============================] - 423s 4s/step - loss: 0.4144 - accuracy: 0.8120 - val_loss: 0.4953 - val_accuracy: 0.7591\n",
      "Epoch 3/5\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8610\n",
      "Epoch 3: val_loss did not improve from 0.49533\n",
      "103/103 [==============================] - 425s 4s/step - loss: 0.3329 - accuracy: 0.8610 - val_loss: 0.5400 - val_accuracy: 0.7608\n",
      "Epoch 4/5\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2629 - accuracy: 0.8968\n",
      "Epoch 4: val_loss did not improve from 0.49533\n",
      "103/103 [==============================] - 426s 4s/step - loss: 0.2629 - accuracy: 0.8968 - val_loss: 0.6115 - val_accuracy: 0.7678\n",
      "Epoch 5/5\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.9238\n",
      "Epoch 5: val_loss did not improve from 0.49533\n",
      "103/103 [==============================] - 426s 4s/step - loss: 0.2045 - accuracy: 0.9238 - val_loss: 0.6881 - val_accuracy: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de390593d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train ,batch_size = 32, epochs = 5 ,validation_data=(X_test,Y_test) , callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "conceptual-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 15s 770ms/step - loss: 0.4953 - accuracy: 0.7591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49533092975616455, 0.7590987682342529]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('hasoc_a_2.h5')\n",
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facial-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 15s 791ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "right-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = []\n",
    "for i in Y_true:\n",
    "    if i =='NOT':\n",
    "        y_actual.append(1)\n",
    "    else :\n",
    "        y_actual.append(0)\n",
    "\n",
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "anticipated-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       380\n",
      "           1       0.67      0.58      0.62       197\n",
      "\n",
      "    accuracy                           0.76       577\n",
      "   macro avg       0.73      0.72      0.72       577\n",
      "weighted avg       0.75      0.76      0.75       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_actual , pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-reduction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-foundation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
