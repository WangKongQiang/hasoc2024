{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Bidirectional,SpatialDropout1D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ultimate-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>task_2</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60c5d6bf5659ea5e55defa2c</td>\n",
       "      <td>PRFN</td>\n",
       "      <td>made amp amp onli abl start make money sustain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60c5d6bf5659ea5e55def461</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>technic still turn back clock dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60c5d6bf5659ea5e55defaad</td>\n",
       "      <td>NONE</td>\n",
       "      <td>govt stop think world media liber gang ani opt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60c5d6bf5659ea5e55def419</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>soldier japan dick head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60c5d6bf5659ea5e55def7fa</td>\n",
       "      <td>OFFN</td>\n",
       "      <td>would better ask think sleazi shitbag lmao</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                       _id task_2  \\\n",
       "0             0  60c5d6bf5659ea5e55defa2c   PRFN   \n",
       "1             1  60c5d6bf5659ea5e55def461   OFFN   \n",
       "2             2  60c5d6bf5659ea5e55defaad   NONE   \n",
       "3             3  60c5d6bf5659ea5e55def419   OFFN   \n",
       "4             4  60c5d6bf5659ea5e55def7fa   OFFN   \n",
       "\n",
       "                                          text_clean  \n",
       "0  made amp amp onli abl start make money sustain...  \n",
       "1            technic still turn back clock dick head  \n",
       "2  govt stop think world media liber gang ani opt...  \n",
       "3                            soldier japan dick head  \n",
       "4         would better ask think sleazi shitbag lmao  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../preprocess_data.csv')\n",
    "data.drop(['task_1','Unnamed: 0','text'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text_clean'].astype(str)\n",
    "tokenizer = Tokenizer(num_words = 1500,split=' ')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequence = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "legitimate-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of unique words :  8255\n",
      "[[   0    0    0 ...  170    3  210]\n",
      " [   0    0    0 ...   72   54   73]\n",
      " [   0    0    0 ...    3   52   13]\n",
      " ...\n",
      " [   0    0    0 ...  817   45  156]\n",
      " [   0    0    0 ...  213   99   38]\n",
      " [   0    0    0 ... 1166  236   57]]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 2500\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "print(\"No of unique words : \",len(index_of_words))\n",
    "\n",
    "X = pad_sequences(sequence , maxlen = max_seq_len )\n",
    "Y = data['task_2']\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "vocabSize = len(index_of_words)\n",
    "lstm_out = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "institutional-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 0)\n",
    "Y_true = Y_test\n",
    "Y_train = pd.get_dummies(Y_train).values\n",
    "Y_test = pd.get_dummies(Y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reasonable-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2500, 256)         2113280   \n",
      "                                                                 \n",
      " spatial_dropout1d (Spatial  (None, 2500, 256)         0         \n",
      " Dropout1D)                                                      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                82176     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2195716 (8.38 MB)\n",
      "Trainable params: 2195716 (8.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabSize, embed_dim,input_length = 2500))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fuzzy-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(\"hasoc_b.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "save_weights_only=False, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noble-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358    NONE\n",
      "2200    HATE\n",
      "2337    PRFN\n",
      "3640    NONE\n",
      "2928    PRFN\n",
      "        ... \n",
      "472     PRFN\n",
      "15      PRFN\n",
      "1813    HATE\n",
      "1721    OFFN\n",
      "3690    PRFN\n",
      "Name: task_2, Length: 577, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alone-launch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False False]\n",
      " [ True False False False]\n",
      " [False False False  True]\n",
      " [False  True False False]\n",
      " [False False False  True]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test[:5])\n",
    "classes = ['HATE','NONE','PRFN','OFFN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "economic-separate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.4755\n",
      "Epoch 1: val_loss improved from inf to 0.42816, saving model to hasoc_b.h5\n",
      "103/103 [==============================] - 555s 5s/step - loss: 0.5058 - accuracy: 0.4755 - val_loss: 0.4282 - val_accuracy: 0.5910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\8888\\Anaconda3\\envs\\pythonProject11\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cf5879b460>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train ,batch_size = 32, epochs = 1 ,validation_data=(X_test,Y_test) , callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frozen-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 12s 642ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guided-damages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06943967 0.8139189  0.0669575  0.04968397]\n",
      " [0.14326045 0.7377507  0.09122909 0.02775968]\n",
      " [0.00333433 0.02223874 0.01973699 0.95468986]\n",
      " ...\n",
      " [0.5987306  0.1771212  0.21319255 0.01095558]\n",
      " [0.457735   0.27838898 0.2265558  0.03732024]\n",
      " [0.00678977 0.05411986 0.03166655 0.90742373]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "handy-times",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 3, 1, 3, 3, 3, 1, 3, 0, 1, 3, 1, 3, 3, 3, 1, 3, 3, 3, 1, 0, 1, 0, 1, 3, 0, 0, 3, 3, 3, 3, 1, 3, 0, 3, 0, 3, 3, 0, 1, 1, 3, 3, 1, 1, 3, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 0, 1, 3, 3, 1, 1, 1, 3, 3, 3, 0, 3, 3, 0, 3, 1, 3, 3, 3, 3, 3, 1, 1, 0, 3, 3, 1, 1, 3, 0, 0, 1, 3, 3, 3, 3, 0, 1, 0, 3, 3, 3, 3, 1, 2, 3, 0, 3, 1, 3, 1, 3, 3, 3, 1, 1, 1, 1, 3, 1, 1, 3, 3, 3, 0, 1, 0, 3, 1, 3, 3, 3, 3, 0, 3, 1, 1, 3, 1, 3, 3, 1, 1, 0, 1, 3, 1, 3, 3, 1, 1, 3, 1, 3, 1, 1, 0, 1, 3, 1, 3, 1, 1, 3, 1, 3, 1, 0, 3, 0, 3, 1, 1, 3, 3, 3, 1, 0, 1, 3, 1, 1, 3, 1, 3, 0, 1, 1, 3, 3, 1, 3, 3, 1, 2, 0, 3, 3, 0, 1, 1, 3, 3, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 1, 0, 0, 3, 3, 3, 1, 3, 1, 3, 1, 1, 1, 0, 1, 3, 3, 3, 3, 1, 3, 3, 1, 1, 1, 3, 3, 1, 1, 3, 0, 3, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 3, 0, 3, 3, 1, 1, 1, 1, 3, 0, 3, 1, 0, 3, 1, 0, 1, 1, 3, 1, 1, 3, 3, 1, 1, 0, 0, 0, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 0, 3, 0, 0, 1, 0, 1, 3, 3, 1, 1, 3, 1, 1, 3, 1, 3, 1, 1, 0, 3, 1, 3, 1, 1, 3, 0, 1, 3, 0, 3, 3, 3, 1, 3, 1, 3, 1, 3, 3, 1, 1, 3, 3, 3, 0, 3, 3, 0, 1, 1, 0, 3, 1, 3, 3, 3, 0, 3, 3, 2, 0, 1, 0, 1, 0, 1, 3, 3, 1, 1, 0, 1, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 0, 3, 3, 3, 3, 1, 0, 3, 1, 1, 1, 3, 3, 1, 0, 1, 3, 1, 3, 3, 3, 1, 3, 0, 1, 1, 1, 3, 0, 1, 3, 1, 3, 1, 1, 3, 0, 1, 3, 1, 1, 3, 1, 3, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 1, 3, 0, 1, 3, 3, 3, 0, 3, 0, 3, 1, 1, 1, 3, 1, 1, 0, 3, 3, 0, 1, 3, 3, 3, 1, 1, 3, 1, 3, 1, 1, 3, 0, 3, 1, 1, 0, 3, 1, 1, 0, 1, 3, 3, 1, 3, 1, 3, 0, 3, 3, 1, 3, 3, 1, 3, 1, 1, 0, 3, 0, 3, 0, 0, 3, 3, 3, 3, 0, 1, 3, 1, 1, 0, 0, 3, 1, 3, 1, 1, 1, 3, 0, 3, 3, 0, 3, 1, 1, 1, 3, 0, 1, 1, 3, 1, 1, 3, 1, 0, 3, 3, 0, 3, 0, 1, 3, 3, 3, 0, 1, 3, 3, 1, 3, 1, 0, 0, 3, 1, 1, 3, 3, 3, 3, 3, 0, 0, 3]\n",
      "[[False  True False False]\n",
      " [False  True False False]\n",
      " [False False False  True]\n",
      " ...\n",
      " [ True False False False]\n",
      " [ True False False False]\n",
      " [False False False  True]]\n"
     ]
    }
   ],
   "source": [
    "pred_class = []\n",
    "for i in Y_pred:\n",
    "    pred_class.append(np.argmax(i))\n",
    "print(pred_class)\n",
    "\n",
    "pred_class = pd.get_dummies(pred_class).values\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blind-pricing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.41      0.42        96\n",
      "           1       0.59      0.64      0.62       197\n",
      "           2       1.00      0.03      0.06       104\n",
      "           3       0.64      0.96      0.77       180\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       577\n",
      "   macro avg       0.67      0.51      0.46       577\n",
      "weighted avg       0.65      0.59      0.53       577\n",
      " samples avg       0.59      0.59      0.59       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test , pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-houston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
